{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch (HuggingFace) BERT for Question Answering on SageMaker\n",
    "\n",
    "TODO: Some kind of intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configurations and connnect to SDKs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier dev of local modules:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import json\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch as PyTorchEstimator\n",
    "from sagemaker.pytorch.model import PyTorchModel, PyTorchPredictor\n",
    "\n",
    "# Local Dependencies:\n",
    "from util import demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"2021-04-gym-bert\"\n",
    "%store BUCKET_NAME\n",
    "\n",
    "SQUAD_V2 = False  # Whether to use V2 (including unanswerable questions)\n",
    "%store SQUAD_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "botosess = boto3.session.Session()\n",
    "region = botosess.region_name\n",
    "s3 = botosess.resource(\"s3\")\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = botosess.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch SQuAD data\n",
    "\n",
    "We'll fetch both the `train` and the `dev` datasets from SQuAD - which are distinct datasets without overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rajpurkar/SQuAD-explorer/master/dataset\"\n",
    "version = \"2.0\" if SQUAD_V2 else \"1.1\"\n",
    "train_raw_filename = f\"train-v{version}.json\"\n",
    "dev_raw_filename = f\"dev-v{version}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data/raw\n",
    "!curl {DOWNLOAD_ROOT}/{train_raw_filename} --output ./data/raw/{train_raw_filename}\n",
    "!curl {DOWNLOAD_ROOT}/{dev_raw_filename} --output ./data/raw/{dev_raw_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate datasets and load in to S3\n",
    "\n",
    "Although SQuAD dev smaller and distinct from train, it's a bit large to make a performant validation dataset - so we'll split it in two to create separate \"validation\" and \"test\" datasets.\n",
    "\n",
    "We assume there's no important correlations in the ordering of the dev dataset - so just take the first few documents as listed for validation and leave the remainder as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/raw/{dev_raw_filename}\", \"r\") as f:\n",
    "    dev_data = json.loads(f.read())\n",
    "\n",
    "n_docs = len(dev_data[\"data\"])\n",
    "n_docs_validation = n_docs // 4  # Only use a quarter of the docs for validation, rest for test\n",
    "\n",
    "val_data = {\n",
    "    \"data\": dev_data[\"data\"][:n_docs_validation],\n",
    "    \"version\": version,\n",
    "}\n",
    "test_data = {\n",
    "    \"data\": dev_data[\"data\"][n_docs_validation:],\n",
    "    \"version\": version,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = f\"SQuAD-train-v{version}.json\"\n",
    "val_filename = f\"SQuAD-validation-v{version}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/raw/{train_raw_filename} data/{train_filename}\n",
    "with open(f\"data/{val_filename}\", \"w\") as f:\n",
    "    f.write(json.dumps(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.Object(f\"data/{train_filename}\").upload_file(f\"data/{train_filename}\")\n",
    "bucket.Object(f\"data/{val_filename}\").upload_file(f\"data/{val_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = f\"s3://{BUCKET_NAME}/data/{train_filename}\"\n",
    "val_channel = f\"s3://{BUCKET_NAME}/data/{val_filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugger_hook_config = sagemaker.debugger.DebuggerHookConfig(\n",
    "    s3_output_path=f\"s3://{BUCKET_NAME}/tensors\",\n",
    "    container_local_output_path=\"/var/tensors\",\n",
    "#     hook_parameters={\n",
    "#         'key': 'value'\n",
    "#     },\n",
    "    collection_configs=[\n",
    "#         sagemaker.debugger.CollectionConfig(\n",
    "#             name=\"custom\",\n",
    "#             parameters={\n",
    "#                 \"key\": \"value\"\n",
    "#             }\n",
    "#         ),\n",
    "        sagemaker.debugger.CollectionConfig(name=\"gradients\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=f\"s3://{BUCKET_NAME}/tensorboard\",\n",
    "    container_local_output_path=\"/var/tensorboard\",\n",
    ")\n",
    "\n",
    "metric_definitions = [\n",
    "    { \"Name\": \"train:Loss\", \"Regex\": r\"Metrics:.* loss=(.*?);\" },\n",
    "    { \"Name\": \"train:LearningRate\", \"Regex\": r\"Metrics:.* lr=(.*?);\" },\n",
    "    { \"Name\": \"validation:Exact\", \"Regex\": r\"Metrics:.* eval_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:F1\", \"Regex\": r\"Metrics:.* eval_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:Total\", \"Regex\": r\"Metrics:.* eval_total=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsExact\", \"Regex\": r\"Metrics:.* eval_NoAns_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsF1\", \"Regex\": r\"Metrics:.* eval_NoAns_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsTotal\", \"Regex\": r\"Metrics:.* eval_NoAns_total=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestExact\", \"Regex\": r\"Metrics:.* eval_best_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestExactThresh\", \"Regex\": r\"Metrics:.* eval_best_exact_thresh=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestF1\", \"Regex\": r\"Metrics:.* eval_best_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestF1Thresh\", \"Regex\": r\"Metrics:.* eval_best_f1_thresh=(.*?);\" },\n",
    "    { \"Name\": \"validation:SecsPerSample\", \"Regex\": r\"Evaluation.* \\((.*?) sec\" },\n",
    "]\n",
    "\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",\n",
    "\n",
    "    base_job_name=\"bert-qna-short\",\n",
    "    checkpoint_s3_uri=f\"s3://{BUCKET_NAME}/checkpoints\",\n",
    "    output_path=f\"s3://{BUCKET_NAME}/jobs\",\n",
    "\n",
    "    framework_version=\"1.4\",\n",
    "    py_version=\"py3\",\n",
    "\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.2xlarge\",\n",
    "    volume_size=100,\n",
    "    max_run=int(1.5*60*60),\n",
    "\n",
    "    \n",
    "    # Checkpoint saving might be part-working but resume definitely isn't yet:\n",
    "    #max_wait=60*60,\n",
    "    #use_spot_instances=True,\n",
    "\n",
    "    #debugger_hook_config=debugger_hook_config,\n",
    "    #tensorboard_output_config=tensorboard_output_config,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "\n",
    "    hyperparameters={\n",
    "        \"checkpoint-interval\": 200,\n",
    "        \"epochs\": 2,  # as configured, max-steps is the limiting factor\n",
    "        \"has-unanswerable\": \"true\" if SQUAD_V2 else \"false\",  # (SM doesn't like bool hyperparams)\n",
    "        \"log-interval\": 200,\n",
    "        \"max-steps\": 2000,\n",
    "        \"per-gpu-eval-batch-size\": 16,\n",
    "        \"seed\": 1337,\n",
    "        #\"log-level\": \"DEBUG\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimator.fit({\n",
    "    \"train\": train_channel,\n",
    "    \"validation\": val_channel,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#estimator = PyTorchEstimator.attach(\"bert-qna-short-2021-04-08-08-44-53-039\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: deploy from estimator .deploy() instead?\n",
    "\n",
    "model_path = estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "model = PyTorchModel(\n",
    "    model_data=model_path,\n",
    "    role=role,\n",
    "    source_dir=\"src/\",\n",
    "    entry_point=\"src/inference.py\",\n",
    "    framework_version=\"1.4\",\n",
    "    py_version = \"py3\"\n",
    ")\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.p2.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or attach to an existing endpoint by endpoint name:\n",
    "#predictor = PyTorchPredictor(\"pytorch-inference-2021-04-08-10-06-52-213\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch predictors default to numpy serialization - so we need to change to JSON for our model:\n",
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We could pass in test_data directly, but let's sort the docs alphabetically by title for navigation:\n",
    "sorteddocs = sorted(test_data[\"data\"], key=lambda d: d[\"title\"])\n",
    "\n",
    "def endpoint_answer_fetcher(context, question):\n",
    "    result = predictor.predict({\n",
    "        \"context\": context,\n",
    "        \"question\": question,\n",
    "    })\n",
    "    return (result[\"start\"], result[\"end\"]), result\n",
    "\n",
    "demo.squad_widget(sorteddocs, endpoint_answer_fetcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
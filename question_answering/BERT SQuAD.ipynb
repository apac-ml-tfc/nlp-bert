{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch (HuggingFace) BERT for Question Answering on SageMaker\n",
    "\n",
    "TODO: Some kind of intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set configurations and connnect to SDKs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For easier dev of local modules:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Python Built-Ins:\n",
    "import json\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.estimator import PyTorch as PyTorchEstimator\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# Local Dependencies:\n",
    "from util import demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'BUCKET_NAME' (str)\n",
      "Stored 'SQUAD_V2' (bool)\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = \"2020-05-gym-bert\"\n",
    "%store BUCKET_NAME\n",
    "\n",
    "SQUAD_V2 = False  # Whether to use V2 (including unanswerable questions)\n",
    "%store SQUAD_V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "botosess = boto3.session.Session()\n",
    "region = botosess.region_name\n",
    "s3 = botosess.resource(\"s3\")\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = botosess.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch SQuAD Data\n",
    "\n",
    "We'll fetch both the `train` and the `dev` datasets from SQuAD - which are distinct datasets without overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28.8M  100 28.8M    0     0   462k      0  0:01:03  0:01:03 --:--:-- 8125k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4740k  100 4740k    0     0  4593k      0  0:00:01  0:00:01 --:--:-- 4593k\n"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/rajpurkar/SQuAD-explorer/master/dataset\"\n",
    "version = \"2.0\" if SQUAD_V2 else \"1.1\"\n",
    "train_raw_filename = f\"train-v{version}.json\"\n",
    "dev_raw_filename = f\"dev-v{version}.json\"\n",
    "\n",
    "!mkdir -p data/raw\n",
    "!curl {DOWNLOAD_ROOT}/{train_raw_filename} --output ./data/raw/{train_raw_filename}\n",
    "!curl {DOWNLOAD_ROOT}/{dev_raw_filename} --output ./data/raw/{dev_raw_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate datasets and load in to S3\n",
    "\n",
    "Although SQuAD dev smaller and distinct from train, it's a bit large to make a performant validation dataset - so we'll split it in two to create separate \"validation\" and \"test\" datasets.\n",
    "\n",
    "We assume there's no important correlations in the ordering of the dev dataset - so just take the first few documents as listed for validation and leave the remainder as test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"data/raw/{dev_raw_filename}\", \"r\") as f:\n",
    "    dev_data = json.loads(f.read())\n",
    "\n",
    "n_docs = len(dev_data[\"data\"])\n",
    "n_docs_validation = n_docs // 4  # Only use a quarter of the docs for validation, rest for test\n",
    "\n",
    "val_data = {\n",
    "    \"data\": dev_data[\"data\"][:n_docs_validation],\n",
    "    \"version\": version,\n",
    "}\n",
    "test_data = {\n",
    "    \"data\": dev_data[\"data\"][n_docs_validation:],\n",
    "    \"version\": version,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = f\"SQuAD-train-v{version}.json\"\n",
    "val_filename = f\"SQuAD-validation-v{version}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp data/raw/{train_raw_filename} data/{train_filename}\n",
    "with open(f\"data/{val_filename}\", \"w\") as f:\n",
    "    f.write(json.dumps(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket.Object(f\"data/{train_filename}\").upload_file(f\"data/{train_filename}\")\n",
    "bucket.Object(f\"data/{val_filename}\").upload_file(f\"data/{val_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = f\"s3://{BUCKET_NAME}/data/{train_filename}\"\n",
    "val_channel = f\"s3://{BUCKET_NAME}/data/{val_filename}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "debugger_hook_config = sagemaker.debugger.DebuggerHookConfig(\n",
    "    s3_output_path=f\"s3://{BUCKET_NAME}/tensors\",\n",
    "    container_local_output_path=\"/var/tensors\",\n",
    "#     hook_parameters={\n",
    "#         'key': 'value'\n",
    "#     },\n",
    "    collection_configs=[\n",
    "#         sagemaker.debugger.CollectionConfig(\n",
    "#             name=\"custom\",\n",
    "#             parameters={\n",
    "#                 \"key\": \"value\"\n",
    "#             }\n",
    "#         ),\n",
    "        sagemaker.debugger.CollectionConfig(name=\"gradients\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=f\"s3://{BUCKET_NAME}/tensorboard\",\n",
    "    container_local_output_path=\"/var/tensorboard\",\n",
    ")\n",
    "\n",
    "metric_definitions = [\n",
    "    { \"Name\": \"train:Loss\", \"Regex\": r\"Metrics:.* loss=(.*?);\" },\n",
    "    { \"Name\": \"train:LearningRate\", \"Regex\": r\"Metrics:.* lr=(.*?);\" },\n",
    "    { \"Name\": \"validation:Exact\", \"Regex\": r\"Metrics:.* eval_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:F1\", \"Regex\": r\"Metrics:.* eval_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:Total\", \"Regex\": r\"Metrics:.* eval_total=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsExact\", \"Regex\": r\"Metrics:.* eval_NoAns_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsF1\", \"Regex\": r\"Metrics:.* eval_NoAns_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:NoAnsTotal\", \"Regex\": r\"Metrics:.* eval_NoAns_total=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestExact\", \"Regex\": r\"Metrics:.* eval_best_exact=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestExactThresh\", \"Regex\": r\"Metrics:.* eval_best_exact_thresh=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestF1\", \"Regex\": r\"Metrics:.* eval_best_f1=(.*?);\" },\n",
    "    { \"Name\": \"validation:BestF1Thresh\", \"Regex\": r\"Metrics:.* eval_best_f1_thresh=(.*?);\" },\n",
    "    { \"Name\": \"validation:SecsPerSample\", \"Regex\": r\"Evaluation.* \\((.*?) sec\" },\n",
    "]\n",
    "\n",
    "estimator = PyTorchEstimator(\n",
    "    entry_point=\"train.py\",\n",
    "    source_dir=\"src\",\n",
    "\n",
    "    base_job_name=\"bert-qna-short\",\n",
    "    checkpoint_s3_uri=f\"s3://{BUCKET_NAME}/checkpoints\",\n",
    "    output_path=f\"s3://{BUCKET_NAME}/jobs\",\n",
    "\n",
    "    framework_version=\"1.4.0\",\n",
    "    py_version=\"py3\",\n",
    "\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.p3.2xlarge\",\n",
    "    train_max_run=int(1.5*60*60),\n",
    "\n",
    "    # Checkpoint saving might be part-working but resume definitely isn't yet:\n",
    "    #train_max_wait=60*60,\n",
    "    #train_use_spot_instances=True,\n",
    "\n",
    "    #debugger_hook_config=debugger_hook_config,\n",
    "    #tensorboard_output_config=tensorboard_output_config,\n",
    "    debugger_hook_config=False,\n",
    "    metric_definitions=metric_definitions,\n",
    "\n",
    "    hyperparameters={\n",
    "        \"checkpoint-interval\": 200,\n",
    "        \"epochs\": 2,  # as configured, max-steps is the limiting factor\n",
    "        \"has-unanswerable\": \"true\" if SQUAD_V2 else \"false\",  # (SM doesn't like bool hyperparams)\n",
    "        \"log-interval\": 200,\n",
    "        \"max-steps\": 2000,\n",
    "        \"per-gpu-eval-batch-size\": 16,\n",
    "        \"seed\": 1337,\n",
    "        #\"log-level\": \"DEBUG\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-06 09:57:58 Starting - Starting the training job...\n",
      "2020-05-06 09:58:00 Starting - Launching requested ML instances.."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-80c4524cde22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m estimator.fit({\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_channel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m })\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3002\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3004\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJOB_COMPLETE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.fit({\n",
    "    \"train\": train_channel,\n",
    "    \"validation\": val_channel,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: deploy from estimator\n",
    "\n",
    "#predictor = estimator.deploy(\n",
    "#    initial_instance_count=1,\n",
    "#    instance_type=\"ml.p2.xlarge\",\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = estimator.latest_training_job.describe()[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "model = PyTorchModel(model_data=model_path, role=role, source_dir='src/', entry_point='src/inference.py', framework_version='1.4.0')\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.p2.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b636321cc6846119d262fe3f756893d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<p><b>🔮 SQuAD Explorer: 🔍</b> Select a document and paragraph; type a question and …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def endpoint_answer_fetcher(context, question):\n",
    "    endpoint_client = boto3.client('sagemaker-runtime')\n",
    "    endpoint_name = model.name\n",
    "    #endpoint_name = \"pytorch-inference-2020-05-06-09-22-27-318\"\n",
    "    content_type = \"application/json\"\n",
    "    payload = json.dumps({\"question\": question, \"context\": context}).encode('utf-8')\n",
    "    response = endpoint_client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name, \n",
    "        ContentType=content_type,\n",
    "        Accept=content_type,\n",
    "        Body=payload\n",
    "    )\n",
    "    result = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    full = {\n",
    "        \"answer\": result['answer'],\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"score\": result['score']\n",
    "    }\n",
    "    return (result['start'], result['end']), json.dumps(full)\n",
    "    \n",
    "demo.squad_widget(test_data, endpoint_answer_fetcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
